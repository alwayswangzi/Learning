#高并发服务器框架

## 1. 为什么使用libevent库？

1. libevent是基于事件驱动的高性能网络库；
2. 轻量，跨平台，专注于网络事件，不像Asio那样过于追求通用化；
3. 支持多种I/O复用技术；
4. 将I/O事件、定时器事件和信号事件有机的统一起来；
5. 支持注册事件的优先级划分。

## 2. 什么是Acceptor？什么是Reactor？为什么要这样设计？

Acceptor是一个主事件循环，专门负责监听套接字，等待客户端的连接。一旦有客户端connect服务器，Acceptor负责接收一个新的socket连接，并且把这个socket描述符注册到Reactor中做进一步处理。

Reactor释义“反应堆”，是一种事件驱动机制。在多Reactor模型下，程序里的每一个I/O线程都有一个事件循环（event loop）用于处理读写和定时器事件。

Reactor调用和普通函数调用的不同之处在于：应用程序不是主动的调用某个API完成处理，而是相反，Reactor倒置了事件处理流程，应用程序需要提供相应的回调接口并注册到Reactor上，如果相应的事件发生，Reactor将主动调用应用程序注册的回调函数。

Reactor模式是编写高性能网络服务器的必备技术之一，它具有如下的优点：

1. 线程数目基本固定，在程序启动的时候配置，不会频繁的创建与销毁，也可以在线程之间调配负载。
2. 响应快，不必为单个同步时间所阻塞，虽然Reactor本身依然是同步的；
3. 编程相对简单，可以最大程度的避免复杂的多线程及同步问题，并且避免了多线程/进程的切换开销；
4. 可扩展性，可以方便的通过增加Reactor实例个数来充分利用CPU资源；
5. 可复用性，Reactor框架本身与具体事件处理逻辑无关，具有很高的复用性。

##3. 为什么要采用处理线程池，它是如何实现的？

这样的设计主要考虑到了I/O带宽需求小，但是CPU计算量较大的连接请求场景。Reactor在完成消息请求的读取之后把计算任务交给线程池去处理，避免Reactor一直阻塞在该连接上，无法接受下一个连接请求。同时这种方法也可以区分任务优先级，可以单独划分一些线程处理紧急的任务。

实现一个线程池主要包括以下4个组成部分：线程管理器、工作线程、任务接口、任务队列。主程序执行入队操作，把任务添加到一个队列里面；池子里的多个工作线程共同对这个队列试图执行出队操作，需要保证同一时刻只有一个线程出队成功。所以我们需要使用互斥锁来保护队列，同时还需要条件变量来处理主线程通知任务到达、工作线程抢夺任务的问题。

当线程处理完之后，会向Reactor注册一个网络socket写事件，Reactor便会将数据发送给客户端，该写事件随即被销毁，不会占用系统资源。

## 4. 有测试过并发数是多少？如何测试的？

ping-pong测试和击鼓传花测试。

1w个长连接。

## 5. 你觉得限制并发性能的瓶颈是什么？还有哪些改进的地方？

I/O吞吐量。其实libevent库的优势更多的在于它统一的事件接口和触发机制，而libevent的I/O受限于eventbuffer的实现机制，因此吞吐量性能不是强项。如果追求更好的I/O吞吐量，一般可以结合其他的机制，比如zero copy等，而不会直接依赖eventbuffer实现。

1. 减少进程切换
2. 减少不必要的锁，降低锁之间的冲突
3. 减少内存的分配与释放
4. 改进I/O模型
5. 使用第三方工具


其实最关键是内存机制，在简单逻辑的大吞吐量的应用环境下面，buffer的使用机制很大程度上决定了吞吐量的大小。在这种测试条件下对吞吐量起决定作用的开销，在现实的复杂应用情景下，往往会退化成非关键开销。（当然在大吞吐量的情景下，无论如何，内存都是相当大的开销，C10K需要相当的关注zero-copy)

很多时候，库是在性能和接口上做一个妥协。牺牲一定的性能来换取更优良的扩展性或者使用上的便利性。例如，ASIO使用level-trigger而不是edge-trigger.


## 6. 为什么要采用长连接？HTTP长连接是如何实现的？

HTTP底层是通过是TCP连接的。由于一个TCP连接的建立和断开需要三次握手和四次挥手的机制，因此在客户端和服务端通信频繁的场景，例如聊天室，实时游戏等，频繁的连接请求会造成网络开销过大，影响通信效率。

直接采用TCP长连接具有一定的局限性。理论上操作系统不会自动关闭socket连接，但是实际情况下网络环境十分复杂，有些网关或者路由器会把长时间没有数据交互的连接强行断掉，而对于网络层来说则完全不知道。

因此需要采用心跳包机制实现。当读取到客户端发送的HTTP报文头部有Keep-Alive字段时，不立即关闭该TCP连接，而是针对该连接注册一个定时器事件，定时器时间定位几十秒，当定时器产生了超时事件之后，服务器向客户端发送一个echo消息，若收到回复则将定时器重新初始化，等待下一次信息交互。若重试几次任收不到任何消息，则认为客户端已经掉线，关闭该socket连接。

## 7. 什么是RPC？采用了什么框架做的？

RPC 是一种进程间通信方式。它允许程序调用另一个地方（通常是共享网络的另一台机器上）的过程或函数，而不用程序员显式编码这个远程调用的细节。即程序员无论是调用本地的还是远程的，本质上编写的调用代码基本相同。

## 8. 为什么要用protobuf，对比其他的呢？

Protobuf是一款非常优秀的库，他定义了一种紧凑的可扩展的二进制消息格式，非常适用于网络传输。Protobuf相对于XML和JSON的优势在于性能和开销：

1. 时间性能。XML格式化（序列化）和XML解析（反序列化）的时间开销是很大的，在很多时间性能要求高的场合，使用XML会很慢。
2. 空间开销。XML和JSON格式为了有较好的可读性，引入了一些冗余的文本信息。据实验，一条消息数据，用protobuf序列化后的大小是json格式的十分之一，xml格式的二十分之一。
3. 方便扩展。

## 9. HTTPS是如何实现的？

HTTP的缺点：

1. 报文使用明文传输；
2. 不验证通信方的身份；
3. 没有报文完整性检查。

HTTPS就是在HTTP基础上通过SSL/TLS进行通信加密、认证和完整性保护。

HTTPS在传输数据之前需要客户端（浏览器）与服务端（网站）之间进行一次握手，在握手过程中将确立双方加密传输数据的密码信息。握手过程如下：

1. 浏览器将自己支持的一套加密规则发送给网站。
2. 网站从中选出一组加密算法与HASH算法，并将自己的身份信息以证书的形式发回给浏览器。证书里面包含了网站地址，加密公钥，以及证书的颁发机构等信息。
3. 获得网站证书之后浏览器要做以下工作：
   1. 验证证书的合法性。
   2. 如果证书受信任，或者是用户接受了不受信的证书，浏览器会生成一串随机数的密码，并用证书中提供的公钥加密。
   3. 使用约定好的HASH计算握手消息，并使用生成的随机数对消息进行加密，最后将之前生成的所有信息发送给网站。
4. 网站接收浏览器发来的数据之后要做以下的操作：
   1. 使用自己的私钥将信息解密取出密码，使用密码解密浏览器发来的握手消息，并验证HASH是否与浏览器发来的一致。
   2. 使用密码加密一段握手消息，发送给浏览器。
5. 浏览器解密并计算握手消息的HASH，如果与服务端发来的HASH一致，此时握手过程结束，之后所有的通信数据将由之前浏览器生成的随机密码并利用对称加密算法进行加密。

HTTPS一般使用的加密与HASH算法如下：

1. 非对称加密算法：RSA，DSA/DSS
2. 对称加密算法：AES，RC4，3DES
3. HASH算法：MD5，SHA1，SHA256

其中非对称加密算法用于在握手过程中加密生成的密码，对称加密算法用于对真正传输的数据进行加密，而HASH算法用于验证数据的完整性。

由于浏览器生成的密码是整个数据加密的关键，因此在传输的时候使用了非对称加密算法对其加密。非对称加密算法会生成公钥和私钥，公钥只能用于加密数据，因此可以随意传输，而网站的私钥用于对数据进行解密，所以网站都会非常小心的保管自己的私钥，防止泄漏。

使用OpenSSL构建自己的认证机构给自己颁发证书，称为自签名证书。浏览器访问的时候会显示“无法确认证书的安全性”
